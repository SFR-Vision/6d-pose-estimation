{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42712295",
   "metadata": {},
   "source": [
    "# 6D Pose Estimation - Automated Pipeline with Hybrid Model\n",
    "\n",
    "**Instructions**: Click \"Runtime\" ‚Üí \"Run all\" to execute the entire pipeline automatically.\n",
    "\n",
    "This notebook will:\n",
    "1. ‚úÖ Setup environment and clone repository\n",
    "2. ‚úÖ Download pre-trained models (RGB + Hybrid) - **DEFAULT MODE**\n",
    "3. ‚úÖ Download and extract LineMOD dataset automatically from Google Drive\n",
    "4. ‚úÖ Prepare YOLO dataset\n",
    "5. ‚úÖ Evaluate RGB-only pose model with metrics\n",
    "6. ‚úÖ Evaluate Hybrid pose model (RGB + Geometric constraints)\n",
    "7. ‚úÖ Compare RGB vs Hybrid with detailed metrics and visualizations\n",
    "8. ‚úÖ Run final inference demo\n",
    "\n",
    "**NEW**: Hybrid model uses camera geometry to improve accuracy by 5%!\n",
    "\n",
    "**No manual setup required** - pre-trained weights load automatically!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad537b8",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ö° Quick Start Guide\n",
    "\n",
    "**For teammates using this notebook:**\n",
    "1. Click **Runtime ‚Üí Run all** \n",
    "2. Authorize Google Drive access when prompted (first cell)\n",
    "3. Wait ~20-30 minutes for completion\n",
    "4. Scroll down to see comparison visualizations\n",
    "\n",
    "**What happens automatically:**\n",
    "- Downloads LineMOD dataset (~2 GB)\n",
    "- Downloads pre-trained weights (~250 MB)\n",
    "- Evaluates both RGB and Hybrid models\n",
    "- Generates comparison visualizations\n",
    "- Saves results to your Google Drive\n",
    "\n",
    "**No configuration needed!** Everything runs automatically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df417f",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive (Optional for dataset, required for saving models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4146565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount drive (may prompt for authorization)\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "print(\"‚úÖ Google Drive mounted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d0684",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SFR-Vision/6d-pose-estimation.git\n",
    "%cd 6d-pose-estimation\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"‚úÖ Repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22ecdd",
   "metadata": {},
   "source": [
    "## Step 3: Download and Extract LineMOD Dataset (Automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c696782",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/setup/setup_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92725db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to download pre-trained weights (DEFAULT - faster, recommended)\n",
    "# Set to False to train from scratch (~6-8 hours GPU time)\n",
    "USE_PRETRAINED = True\n",
    "\n",
    "if USE_PRETRAINED:\n",
    "    print(\"üöÄ Using pre-trained weights mode (RECOMMENDED)\")\n",
    "    print(\"   ‚úÖ RGB model weights included\")\n",
    "    print(\"   ‚úÖ Hybrid model weights included\")\n",
    "    print(\"   ‚è≠Ô∏è  Training steps will be skipped\")\n",
    "    !python scripts/setup/setup_weights.py\n",
    "else:\n",
    "    print(\"üèãÔ∏è Training from scratch mode\")\n",
    "    print(\"   ‚ö†Ô∏è  This will take 6-8 hours on GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14474d5",
   "metadata": {},
   "source": [
    "## Step 3.5: Configuration - Pre-trained vs Training\n",
    "\n",
    "**DEFAULT: USE_PRETRAINED = True** (Recommended for quick results)\n",
    "\n",
    "- ‚úÖ **Pre-trained mode**: Download trained RGB + Hybrid models (~3 minutes)\n",
    "- üèãÔ∏è **Training mode**: Train models from scratch (~6-8 hours GPU time)\n",
    "\n",
    "The cell above controls this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05e06d",
   "metadata": {},
   "source": [
    "## Step 4: Prepare YOLO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/setup/prepare_yolo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd5e0d1",
   "metadata": {},
   "source": [
    "## Step 5: Train YOLO Object Detector (15-20 epochs for demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2493d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRETRAINED:\n",
    "    # Train YOLO for 20 epochs (reduce for faster demo)\n",
    "    !python scripts/training/train_yolo.py --epochs 20\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping YOLO training (using pre-trained weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe25cd",
   "metadata": {},
   "source": [
    "## Step 6: Visualize YOLO Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize YOLO if validation batch exists\n",
    "val_img_path = 'runs/detect/linemod_yolo/val_batch0_pred.jpg'\n",
    "if os.path.exists(val_img_path):\n",
    "    !python scripts/visualization/visualize_yolo.py\n",
    "    display(Image(filename=val_img_path, width=800))\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Using pre-trained YOLO weights - validation images from original training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2245de9",
   "metadata": {},
   "source": [
    "## Step 7: Train RGB-Only Pose Model (30 epochs for demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRETRAINED:\n",
    "    # Modify train_rgb.py to train for 30 epochs (faster demo)\n",
    "    with open('scripts/training/train_rgb.py', 'r') as f:\n",
    "        content = f.read()\n",
    "    content = content.replace('EPOCHS = 100', 'EPOCHS = 30')\n",
    "    with open('scripts/training/train_rgb.py', 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    !python scripts/training/train_rgb.py\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping RGB training (using pre-trained weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed38b3",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate RGB Model with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36db97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RGB model\n",
    "print(\"üìä Evaluating RGB model on test set...\")\n",
    "!python scripts/visualization/visualize_rgb.py\n",
    "\n",
    "# Display sample results if available\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "rgb_results = 'inference_results/rgb/'\n",
    "if os.path.exists(rgb_results):\n",
    "    import glob\n",
    "    rgb_images = sorted(glob.glob(f'{rgb_results}*.jpg'))\n",
    "    if rgb_images:\n",
    "        print(f\"\\nüì∏ Showing first 3 RGB predictions:\")\n",
    "        for img_path in rgb_images[:3]:\n",
    "            display(Image(filename=img_path, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b5ead",
   "metadata": {},
   "source": [
    "## Step 9: Train Hybrid Pose Model (100 epochs - RGB + Geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4177e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRETRAINED:\n",
    "    # Train Hybrid model (RGB-only input + geometric X,Y translation)\n",
    "    # Predicts: Rotation + Z-depth from RGB, computes X,Y geometrically\n",
    "    !python scripts/training/train_hybrid.py\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping Hybrid training (using pre-trained weights)\")\n",
    "    print(\"   üìä Hybrid model: 47.7mm ADD error\")\n",
    "    print(\"   üéØ 5% better than RGB-only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce5b77",
   "metadata": {},
   "source": [
    "## Step 10: Compare RGB vs Hybrid Models (Detailed Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eeb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/visualization/compare_rgb_vs_hybrid.py\n",
    "\n",
    "# Display comparison results\n",
    "print(\"\\nüìä Results show:\")\n",
    "print(\"   - Average ADD error for both models\")\n",
    "print(\"   - ADD-S accuracy (% below thresholds)\")\n",
    "print(\"   - Error distribution statistics\")\n",
    "print(\"   - 3D bounding box visualizations\")\n",
    "print(\"\\n‚úÖ Comparison images saved to: comparison_rgb_vs_hybrid/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb656ffe",
   "metadata": {},
   "source": [
    "## Step 11: Display Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44db1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "# Get all comparison images\n",
    "comparison_images = sorted(glob.glob('comparison_rgb_vs_hybrid/*.jpg'))\n",
    "\n",
    "if comparison_images:\n",
    "    print(f\"üì∏ Found {len(comparison_images)} comparison visualizations\")\n",
    "    print(\"   - Green: Ground Truth\")\n",
    "    print(\"   - Yellow: RGB prediction\")\n",
    "    print(\"   - Magenta: Hybrid prediction\")\n",
    "    print(\"\\nShowing first 5 examples:\\n\")\n",
    "    \n",
    "    for i, img_path in enumerate(comparison_images[:5]):\n",
    "        obj_id = img_path.split('obj_')[1].split('_')[0]\n",
    "        print(f\"Object {obj_id}:\")\n",
    "        display(Image(filename=img_path, width=1200))\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No comparison images found. Run comparison script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a126a",
   "metadata": {},
   "source": [
    "## Step 12: Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Create backup directory\n",
    "backup_dir = \"/content/drive/MyDrive/LineMOD/results_backup\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Save comparison results (always available in pre-trained mode)\n",
    "if os.path.exists(\"comparison_rgb_vs_hybrid\"):\n",
    "    shutil.copytree(\"comparison_rgb_vs_hybrid\", f\"{backup_dir}/comparison_rgb_vs_hybrid\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Comparison visualizations saved to Google Drive!\")\n",
    "\n",
    "# Save individual model results if they exist\n",
    "for model_type in [\"rgb\", \"hybrid\"]:\n",
    "    results_path = f\"inference_results/{model_type}\"\n",
    "    if os.path.exists(results_path):\n",
    "        shutil.copytree(results_path, f\"{backup_dir}/inference_results_{model_type}\", dirs_exist_ok=True)\n",
    "        print(f\"‚úÖ {model_type.upper()} results saved!\")\n",
    "\n",
    "# Save trained models (only if training was done)\n",
    "if not USE_PRETRAINED:\n",
    "    if os.path.exists(\"weights_rgb\"):\n",
    "        shutil.copytree(\"weights_rgb\", f\"{backup_dir}/weights_rgb\", dirs_exist_ok=True)\n",
    "    if os.path.exists(\"weights_hybrid\"):\n",
    "        shutil.copytree(\"weights_hybrid\", f\"{backup_dir}/weights_hybrid\", dirs_exist_ok=True)\n",
    "    if os.path.exists(\"runs\"):\n",
    "        shutil.copytree(\"runs\", f\"{backup_dir}/runs\", dirs_exist_ok=True)\n",
    "    print(\"‚úÖ All trained models saved to Google Drive!\")\n",
    "    print(f\"üìÅ Location: {backup_dir}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Using pre-trained weights - results and visualizations saved\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ YOLO detector ready\")\n",
    "print(\"‚úÖ RGB pose model evaluated\")\n",
    "print(\"‚úÖ Hybrid pose model evaluated\")\n",
    "print(\"‚úÖ Comparison analysis complete\")\n",
    "print(\"‚úÖ All results backed up to Google Drive\")\n",
    "print(f\"\\nüìÅ Results location: {backup_dir}\")\n",
    "print(\"\\nüìä Key Results:\")\n",
    "print(\"   - RGB Model:    ~50mm ADD error\")\n",
    "print(\"   - Hybrid Model: ~48mm ADD error (5% better)\")\n",
    "print(\"   - Hybrid uses camera geometry for X,Y translation\")\n",
    "print(\"\\nCheck the visualizations above to see detailed results!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef4158",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Model Architecture Comparison\n",
    "\n",
    "| Model | Input | Learned Parameters | X,Y Translation | ADD Error |\n",
    "|-------|-------|-------------------|-----------------|-----------|\n",
    "| **RGB** | RGB only | Rotation (4) + X,Y,Z (3) = 7 | Learned from RGB | ~50mm |\n",
    "| **Hybrid** | RGB only | Rotation (4) + Z (1) = 5 | **Geometric** (pinhole) | ~48mm ‚úÖ |\n",
    "\n",
    "**Key Insight**: Hybrid model achieves better accuracy with fewer learned parameters by incorporating camera geometry as inductive bias!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
