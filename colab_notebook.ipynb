{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6D Object Pose Estimation - Project Demonstration\n",
                "\n",
                "**Click Runtime → Run all to see the complete project in action.**\n",
                "\n",
                "This notebook demonstrates 4 different pose estimation approaches:\n",
                "1. **RGB** - Baseline, learns all 7 pose parameters from RGB\n",
                "2. **RGB-Geometric** - Learns rotation + Z-depth, computes X,Y geometrically\n",
                "3. **RGBD** - Uses RGB + Depth with cross-modal attention\n",
                "4. **RGBD-Geometric** - Learns rotation only, gets translation from depth\n",
                "\n",
                "**No training required** - pre-trained weights are downloaded automatically."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 1: Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository and install dependencies\n",
                "!git clone https://github.com/SFR-Vision/6d-pose-estimation.git\n",
                "%cd 6d-pose-estimation\n",
                "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
                "!pip install -q ultralytics opencv-python scipy matplotlib pyyaml tqdm gdown\n",
                "print(\"Environment ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 2: Download LineMOD Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import gdown\n",
                "import zipfile\n",
                "\n",
                "DATASET_DIR = \"datasets/Linemod_preprocessed\"\n",
                "DATASET_URL = \"https://drive.google.com/uc?id=1kAYxvqXQFQJ4o0TdXrL9xplNZ3TldU7R\"\n",
                "\n",
                "if not os.path.exists(f\"{DATASET_DIR}/data\"):\n",
                "    print(\"Downloading LineMOD dataset (~2GB)...\")\n",
                "    os.makedirs(\"datasets\", exist_ok=True)\n",
                "    gdown.download(DATASET_URL, \"datasets/linemod.zip\", quiet=False)\n",
                "    \n",
                "    print(\"Extracting...\")\n",
                "    with zipfile.ZipFile(\"datasets/linemod.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\"datasets/\")\n",
                "    os.remove(\"datasets/linemod.zip\")\n",
                "    print(\"Dataset ready\")\n",
                "else:\n",
                "    print(\"Dataset already exists\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 3: Download Pre-trained Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gdown\n",
                "import zipfile\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "WEIGHTS_URL = \"https://drive.google.com/uc?id=1OXb0ZYGAID3x8idGU-lPMVb5J0tSzBHN\"\n",
                "\n",
                "if \"YOUR_FILE_ID_HERE\" in WEIGHTS_URL:\n",
                "    print(\"ERROR: Please update WEIGHTS_URL with your Google Drive link!\")\n",
                "else:\n",
                "    print(\"Downloading pre-trained weights...\")\n",
                "    gdown.download(WEIGHTS_URL, \"pretrained_weights.zip\", quiet=False)\n",
                "    \n",
                "    print(\"Extracting weights...\")\n",
                "    with zipfile.ZipFile(\"pretrained_weights.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\"_temp_weights\")\n",
                "    \n",
                "    for folder in os.listdir(\"_temp_weights\"):\n",
                "        src = f\"_temp_weights/{folder}\"\n",
                "        if folder == \"yolo_weights\":\n",
                "            dest = \"runs/detect/linemod_yolo/weights\"\n",
                "        else:\n",
                "            dest = folder\n",
                "        os.makedirs(dest, exist_ok=True)\n",
                "        for file in os.listdir(src):\n",
                "            shutil.copy2(f\"{src}/{file}\", f\"{dest}/{file}\")\n",
                "        print(f\"  Extracted: {dest}\")\n",
                "    \n",
                "    shutil.rmtree(\"_temp_weights\")\n",
                "    os.remove(\"pretrained_weights.zip\")\n",
                "    print(\"All weights ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 4: Prepare YOLO Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "if not os.path.exists(\"datasets/yolo_ready\"):\n",
                "    !python scripts/setup/prepare_yolo.py\n",
                "else:\n",
                "    print(\"YOLO dataset already prepared\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 5: Compare All 4 Models (Metrics)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%run scripts/visualization/compare_all_models.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 6: Visual Comparison - 3D Bounding Boxes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Green = Ground Truth, Colored = Model predictions\")\n",
                "%run scripts/visualization/compare_visual.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 7: YOLO Object Detection Demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%run scripts/visualization/visualize_yolo.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 8: Individual Model Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"1. RGB Model - Learns full pose (7 params) from RGB only\")\n",
                "%run scripts/inference/inference_rgb.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"2. RGB-Geometric Model - Learns rotation + Z (5 params), computes X,Y geometrically\")\n",
                "%run scripts/inference/inference_rgb_geometric.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"3. RGBD Model - Uses RGB + Depth with cross-modal attention (7 params)\")\n",
                "%run scripts/inference/inference_rgbd.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"4. RGBD-Geometric Model - Learns rotation only (4 params), translation from depth\")\n",
                "%run scripts/inference/inference_rgbd_geometric.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Results Summary\n",
                "\n",
                "| Model | Input | Learned Params | Key Idea |\n",
                "|-------|-------|----------------|----------|\n",
                "| **RGB** | RGB | 7 (rot + x,y,z) | Baseline |\n",
                "| **RGB-Geometric** | RGB | 5 (rot + z) | Geometric X,Y |\n",
                "| **RGBD** | RGB+D | 7 (rot + x,y,z) | Cross-modal fusion |\n",
                "| **RGBD-Geometric** | RGB+D | 4 (rot only) | Depth → Translation |\n",
                "\n",
                "**Key Finding:** Geometric constraints reduce learned parameters while improving accuracy!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Project Structure\n",
                "\n",
                "```\n",
                "6d-pose-estimation/\n",
                "├── models/              # Neural network architectures\n",
                "├── data/                # Dataset loaders\n",
                "├── utils/               # Shared utilities\n",
                "├── scripts/\n",
                "│   ├── training/        # Training scripts\n",
                "│   ├── visualization/   # Visualization scripts\n",
                "│   └── inference/       # Inference scripts\n",
                "└── weights_*/           # Pre-trained models\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
